{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cluster.tools","text":"<p>The cluster.tools core is an orchestration tool for developers looking to simplify their development and operation of extract-transform-load (etl) functions. </p>"},{"location":"#why-use-clustertools","title":"Why use Cluster.tools?","text":"<p>Cluster.tools was developed from an operators perspective. When developing functions distributed in a private, public, or hybrid network what is the easiest way to version manage, load balance, monitor, and control access to these functions.</p> <p>A standard interface definition using HTTP and JSON also allows you to create a wrapper on top of any software so that it can interface with cluster.tools. </p>"},{"location":"#what-are-some-use-cases","title":"What are some Use Cases?","text":"<ol> <li>I want to load balance requests across several distributed deployments.</li> <li>I want to dynamically control access to functions in case of unexpected behavior.</li> <li>I want to update one unit of code without affecting service to unrelated units.</li> <li>I want to track the amount of data processed and how long it took.</li> <li>I want a central location to receive logs from distributed processes.</li> <li>I want a central configuration management solution that can be distributed across functions.</li> </ol>"},{"location":"#why-did-you-start-this","title":"Why did you start this?","text":"<p>Cluster.tools was started in parallel with a separate project to handle deploying etl functions in golang. Over time it evolved into its own project that is continued to this day.</p>"},{"location":"#some-guides","title":"Some Guides","text":"<ol> <li>Getting Start in 15 Minutes</li> <li>Implementing Processors</li> </ol>"},{"location":"in15min/","title":"Get Upto Speed in 15 Minutes","text":"<p>The cluster.tools core is a cloud orchestration tool for Lambda and ETL functions. The power of the core is through handling multiple functionalities that are required for cloud pipelines but distract developers from building the transformations functions that are most important for business or product requirements.</p> <p>[show core and processors]</p> <p>It is important to note that the core itself does not provision (execute) any code itself, but rather is responsible for distributing calls to executables called processors that are responsible for providing a common interface for the core to call code. The interface between the core and processor is an HTTP REST API that accepts data in a JSON format for sending/receiving content. The details of the interface are described in more detail within the processor page.</p> <p>[what is a cluster, how it works]</p> <p>[how modules isolate clusters]</p> <p>[versioning to support multiple versions]</p> <p>[mounting / unmounting]</p> <p>[provisioning]</p> <p>Some of the functionality includes: 1. Dynamic Registering of Processors 2. Encapsulation/Isolation of Code into Register-able Modules  3. Module Versioning 4. Dynamic Availability through Mounting and Unmounting 4. Remote Procedure Calls 5. Load Balancing Across Processors with a common registered module 3. Configuration Management 4. Short Term Caching 5. Statistic Monitoring</p>"},{"location":"processors/","title":"Processors","text":"<p>Processors are separate programs responsible for registering to a cluster.tools core and accepting incoming provision requests.</p> <p>The core and processor communicate by exchanging messages over HTTP REST endpoints encoding objects using JSON within the request or response body.</p> <p>Anyone can developer their own processor as long as it implements the interface defined by the core. This page documents the use cases and interfaces you can use as a guide to create your own processor.</p> <p>If you have implemented an interface for a new language and wish to add it to this page, raise a pull request on the wiki repository.</p> Language Developer Repository Template Golang Gabriel Cordovado https://github.com/GabeCordo/processor-framework goto"},{"location":"processors/#basic-implementation","title":"Basic Implementation","text":""},{"location":"processors/#how-does-the-processor-communicate-with-the-core","title":"How does the processor communicate with the core?","text":"<p>The processor must implement a series of functions to register itself and its callable functions with the core. Its the equipment of letting the core know you exist and what its allowed to ask you to run.</p>"},{"location":"processors/#connect-request","title":"Connect Request","text":"<p>When the processor binary is started it shall create a new processor record on the core. The processor record holds two pieces of information, (1) the address the core should use when sending messages to the processor, (2) the port the processor is listening for incoming http requests.   </p>"},{"location":"processors/#post-httplocalhost8137processor","title":"POST http://localhost:8137/processor","text":"<pre><code>{\n    \"host\": \"localhost\",\n    \"port\": 5023\n}\n</code></pre>"},{"location":"processors/#register-module-request","title":"Register Module Request","text":"<p>When the processor binary is ready to receive requests from the core it shall create a module record. The module is a grouping of functions that share a common logical purpose. Modules also contain associative metadata like version and developer contact information so a user can better understand what they are using.</p> <p>In the example below, we are registering a module called common that contains one function Vec. We set the on-load specifier to batch signifying that it should be user callable.</p>"},{"location":"processors/#post-httplocalhost8137module","title":"POST http://localhost:8137/module","text":"<pre><code>{\n    \"host\": \"localhost\",\n    \"port\": 5023,\n    \"module\": {\n        \"config\": {\n            \"name\": \"common\",\n            \"version\": 1,\n            \"contact\": {\n                \"name\": \"James Bond\",\n                \"email\": \"james.bond@gmail.com\"\n            },\n            \"exports\": [\n                {\n                \"cluster\": \"Vec\",\n                \"mount\": true,\n                \"config\": {\n                    \"mode\": \"Batch\",\n                    \"on-crash\": \"DoNothing\",\n                    \"on-load\": \"WaitAndPush\",\n                    \"static\": {\n                    \"t-functions\": 1,\n                    \"l-functions\": 1\n                    },\n                    \"dynamic\": {\n                    \"t-function\": {\n                        \"threshold\": 2,\n                        \"growth-factor\": 2\n                    },\n                    \"l-function\": {\n                        \"threshold\": 2,\n                        \"growth-factor\": 2\n                    }\n                    }\n                }\n                }\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"processors/#sending-updates-to-the-core","title":"Sending Updates to the Core","text":"<p>TODO</p>"},{"location":"processors/#how-does-the-core-communicate-with-the-processor","title":"How does the core communicate with the processor?","text":"<p>The processor must implement an HTTP endpoint to receive run requests from the core.</p>"},{"location":"processors/#incoming-run-request","title":"Incoming Run Request","text":""},{"location":"processors/#post-httpprocessor-urlsupervisor","title":"POST http://processor-url/supervisor","text":"<pre><code>{\n    \"module\": \"name\",\n    \"cluster\": \"function-name\",\n    \"config\": \"config-name\",\n    \"supervisor\": 0, // reference # of the run\n    \"metadata\": {\n        \"key\": \"value\"  // per-run parameters\n    }\n}\n</code></pre>"},{"location":"processors/#advanced-implementation","title":"Advanced Implementation","text":"<p>TODO</p>"},{"location":"processors/#logging","title":"Logging","text":"<p>TODO</p>"},{"location":"processors/#caching","title":"Caching","text":"<p>TODO</p>"},{"location":"components/cache/","title":"Cache","text":""},{"location":"components/cache/#cache","title":"Cache","text":"<p>The ETL Framework has a built-in solution for caching intermediate data that is used in a chain of sequential ETL clusters. This is an alternative to loading and storing data in an external database solution that introduces networking errors and latency.</p>"},{"location":"components/cache/#ensuring-the-cache-is-enabled","title":"Ensuring the Cache is Enabled","text":"<p>When starting up the ETL Framework on debug mode, you should see a system log notifying you that the cache thread has started.</p> <p><code>2023/01/25 12:37:45 (+) Cache Thread Started</code></p>"},{"location":"components/cache/#cache-lifetime","title":"Cache Lifetime","text":"<p>Cache data is intended for short lifetime storage. This is to handle that the cache resides in system memory (which is usually limited) and that permanent or long-term storage of data should be left to other database solutions.</p> <p>By Default Cache Records Have a Lifetime of 1 Minute</p>"},{"location":"components/cache/#modifying-the-cache-lifetime","title":"Modifying the Cache Lifetime","text":"<p>The ETLConfig contains am \"expire-in\" field which specifies how many minutes should pass before a record is automatically removed from the cache.</p> <pre><code>{\n   \"cache\": {\n      \"expire-in\": 1\n   }\n}\n</code></pre>"},{"location":"components/cache/#cache-memory-usage","title":"Cache Memory Usage","text":"<p>The cache resides in the system memory which means that the storage capabilities are highly limited versus traditional database solutions that use disk storage. It is important we keep track of the number of cached values we store on the ETL Cache in case developers don't realize how much data their clusters are generating, or it is being misused as a black box for data storage.</p> <p>By Default Cache Records Have a Limit of 1000 Records If we have records storing 1MB of data, that is already using 1GB of system memory if maxed out.</p>"},{"location":"components/cache/#modifying-the-memory-usage","title":"Modifying the Memory Usage","text":"<p>The ETLConfig contains a \"max-size\" field in the \"cache\" section to change the max number of records allowed.</p> <pre><code>{\n   \"cache\": {\n      \"max-size\": 1000\n   }\n}\n</code></pre>"}]}