{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to cluster.tools","text":"<p>The cluster.tools core is a cloud orchestration tool for Lambda and ETL functions. The power of the core is through handling multiple functionalities that are required for cloud pipelines but distract developers from building the transformations functions that are most important for business or product requirements.</p> <p>[show core and processors]</p> <p>It is important to note that the core itself does not provision (execute) any code itself, but rather is responsible for distributing calls to executables called processors that are responsible for providing a common interface for the core to call code. The interface between the core and processor is an HTTP REST API that accepts data in a JSON format for sending/receiving content. The details of the interface are described in more detail within the processor page.</p> <p>[what is a cluster, how it works]</p> <p>[how modules isolate clusters]</p> <p>[versioning to support multiple versions]</p> <p>[mounting / unmounting]</p> <p>[provisioning]</p> <p>Some of the functionality includes: 1. Dynamic Registering of Processors 2. Encapsulation/Isolation of Code into Register-able Modules  3. Module Versioning 4. Dynamic Availability through Mounting and Unmounting 4. Remote Procedure Calls 5. Load Balancing Across Processors with a common registered module 3. Configuration Management 4. Short Term Caching 5. Statistic Monitoring</p>"},{"location":"components/cache/","title":"Cache","text":""},{"location":"components/cache/#cache","title":"Cache","text":"<p>The ETL Framework has a built-in solution for caching intermediate data that is used in a chain of sequential ETL clusters. This is an alternative to loading and storing data in an external database solution that introduces networking errors and latency.</p>"},{"location":"components/cache/#ensuring-the-cache-is-enabled","title":"Ensuring the Cache is Enabled","text":"<p>When starting up the ETL Framework on debug mode, you should see a system log notifying you that the cache thread has started.</p> <p><code>2023/01/25 12:37:45 (+) Cache Thread Started</code></p>"},{"location":"components/cache/#cache-lifetime","title":"Cache Lifetime","text":"<p>Cache data is intended for short lifetime storage. This is to handle that the cache resides in system memory (which is usually limited) and that permanent or long-term storage of data should be left to other database solutions.</p> <p>By Default Cache Records Have a Lifetime of 1 Minute</p>"},{"location":"components/cache/#modifying-the-cache-lifetime","title":"Modifying the Cache Lifetime","text":"<p>The ETLConfig contains am \"expire-in\" field which specifies how many minutes should pass before a record is automatically removed from the cache.</p> <pre><code>{\n   \"cache\": {\n      \"expire-in\": 1\n   }\n}\n</code></pre>"},{"location":"components/cache/#cache-memory-usage","title":"Cache Memory Usage","text":"<p>The cache resides in the system memory which means that the storage capabilities are highly limited versus traditional database solutions that use disk storage. It is important we keep track of the number of cached values we store on the ETL Cache in case developers don't realize how much data their clusters are generating, or it is being misused as a black box for data storage.</p> <p>By Default Cache Records Have a Limit of 1000 Records If we have records storing 1MB of data, that is already using 1GB of system memory if maxed out.</p>"},{"location":"components/cache/#modifying-the-memory-usage","title":"Modifying the Memory Usage","text":"<p>The ETLConfig contains a \"max-size\" field in the \"cache\" section to change the max number of records allowed.</p> <pre><code>{\n   \"cache\": {\n      \"max-size\": 1000\n   }\n}\n</code></pre>"}]}